{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "historic-trainer",
      "metadata": {
        "id": "historic-trainer"
      },
      "source": [
        "# Activity 2.1 : Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "olive-manner",
      "metadata": {
        "id": "olive-manner"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to introduce how to build a convolutional neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "happy-transport",
      "metadata": {
        "id": "happy-transport"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train convolutional neural network\n",
        "* Evaluate the accuracy and loss of the model using convolutional neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "leading-providence",
      "metadata": {
        "id": "leading-providence"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "* CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "literary-trail",
      "metadata": {
        "id": "literary-trail"
      },
      "source": [
        "#### Procedures\n",
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "stretch-active",
      "metadata": {
        "id": "stretch-active"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "collaborative-seating",
      "metadata": {
        "id": "collaborative-seating"
      },
      "source": [
        "* Shuffle the data\n",
        "* Split the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "modular-springer",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "modular-springer",
        "outputId": "2afef46e-7f7c-421a-aecc-6e46802ca33e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "female-carolina",
      "metadata": {
        "id": "female-carolina"
      },
      "source": [
        "Check the image size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "alleged-stephen",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alleged-stephen",
        "outputId": "481511e6-e665-4adf-a6e1-cf3196dcabc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\n",
        "x_train[444].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conscious-twenty",
      "metadata": {
        "id": "conscious-twenty"
      },
      "source": [
        "Visualize one of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "positive-creation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "positive-creation",
        "outputId": "65ca1014-601a-4032-faa8-69da2158ad10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(y_train[444])\n",
        "plt.imshow(x_train[444]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "animated-rotation",
      "metadata": {
        "id": "animated-rotation"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "severe-filing",
      "metadata": {
        "id": "severe-filing"
      },
      "source": [
        "Instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "genetic-centre",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "genetic-centre",
        "outputId": "d5b1c86c-4615-4d3d-9900-dfd3bd8e0c47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "y_train[444]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "detected-education",
      "metadata": {
        "id": "detected-education"
      },
      "source": [
        "Convert to float and scale the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "familiar-damages",
      "metadata": {
        "id": "familiar-damages"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bizarre-smith",
      "metadata": {
        "id": "bizarre-smith"
      },
      "source": [
        "Build a CNN using Keras Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "understanding-milan",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "understanding-milan",
        "outputId": "66e1a49c-1f5c-401f-d918-6321969654f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 16, 16, 32)        2432      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 6, 6, 32)          25632     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 6, 6, 32)          0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 3, 3, 32)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 3, 3, 32)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 288)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               147968    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181162 (707.66 KB)\n",
            "Trainable params: 181162 (707.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model_1 = Sequential()\n",
        "\n",
        "\n",
        "## 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## 2x2 max pooling reduces to 3 x 3 x 32\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.25))\n",
        "\n",
        "## Flatten turns 3x3x32 into 288x1\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(512))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(num_classes))\n",
        "model_1.add(Activation('softmax'))\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baking-portable",
      "metadata": {
        "id": "baking-portable"
      },
      "source": [
        "* Use batch size of 32\n",
        "* Initiate RMSprop optimizer\n",
        "* Train the model using RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "removed-memorial",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "removed-memorial",
        "outputId": "fa9bf01c-4e90-49b1-abda-725d91359e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 34s 21ms/step - loss: 1.7022 - accuracy: 0.3791 - val_loss: 1.3888 - val_accuracy: 0.5057\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 34s 22ms/step - loss: 1.4462 - accuracy: 0.4847 - val_loss: 1.3171 - val_accuracy: 0.5244\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 33s 21ms/step - loss: 1.3678 - accuracy: 0.5144 - val_loss: 1.3094 - val_accuracy: 0.5404\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 1.3227 - accuracy: 0.5340 - val_loss: 1.2316 - val_accuracy: 0.5705\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 53s 34ms/step - loss: 1.2988 - accuracy: 0.5441 - val_loss: 1.2245 - val_accuracy: 0.5693\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 34s 22ms/step - loss: 1.2826 - accuracy: 0.5516 - val_loss: 1.2162 - val_accuracy: 0.5864\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.2769 - accuracy: 0.5603 - val_loss: 1.1666 - val_accuracy: 0.5981\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 33s 21ms/step - loss: 1.2709 - accuracy: 0.5616 - val_loss: 1.1859 - val_accuracy: 0.5886\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 1.2627 - accuracy: 0.5663 - val_loss: 1.4175 - val_accuracy: 0.5189\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 1.2687 - accuracy: 0.5673 - val_loss: 1.1727 - val_accuracy: 0.5957\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.2799 - accuracy: 0.5673 - val_loss: 1.1920 - val_accuracy: 0.6053\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 1.2750 - accuracy: 0.5696 - val_loss: 1.4549 - val_accuracy: 0.5033\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.2754 - accuracy: 0.5715 - val_loss: 1.2121 - val_accuracy: 0.5909\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 1.2863 - accuracy: 0.5687 - val_loss: 1.5259 - val_accuracy: 0.5199\n",
            "Epoch 15/15\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 1.2996 - accuracy: 0.5625 - val_loss: 1.3439 - val_accuracy: 0.5443\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c36c9ed6080>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005)\n",
        "\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=15,\n",
        "              validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jewish-lambda",
      "metadata": {
        "id": "jewish-lambda"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "southeast-theater",
      "metadata": {
        "id": "southeast-theater"
      },
      "source": [
        "* Build a more complicated model with the following pattern:\n",
        "Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
        "\n",
        "* Use strides of 1 for all convolutional layers.\n",
        "\n",
        "* Write the number of parameters of your model  and compare it to the previous model\n",
        "\n",
        "* Train it for 5 epochs. Commpare the training time, loss and accuracy numbers (on both the training and validation sets)?\n",
        "\n",
        "* Use different structures and run times, and see how accurate your model can be."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "supple_model = Sequential()\n",
        "\n",
        "## 5x5 convolution with 1x1 stride and 32 filters\n",
        "supple_model.add(Conv2D(32, (5, 5), strides=(1, 1), padding='same', input_shape=x_train.shape[1:]))\n",
        "supple_model.add(Activation('relu'))\n",
        "\n",
        "## Another 5x5 convolution with 1x1 stride and 32 filters\n",
        "supple_model.add(Conv2D(32, (5, 5), strides=(1, 1), padding='same'))\n",
        "supple_model.add(Activation('relu'))\n",
        "\n",
        "## 2x2 max pooling reduces to 3 x 3 x 32\n",
        "supple_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "supple_model.add(Dropout(0.25))\n",
        "\n",
        "## Another 5x5 convolution with 1x1 stride and 32 filters\n",
        "supple_model.add(Conv2D(32, (5, 5), strides=(1, 1), padding='same'))\n",
        "supple_model.add(Activation('relu'))\n",
        "\n",
        "## Another 5x5 convolution with 1x1 stride and 32 filters\n",
        "supple_model.add(Conv2D(32, (5, 5), strides=(1, 1), padding='same'))\n",
        "supple_model.add(Activation('relu'))\n",
        "\n",
        "## 2x2 max pooling reduces to 3 x 3 x 32\n",
        "supple_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "supple_model.add(Dropout(0.25))\n",
        "\n",
        "## Flatten turns 3x3x32 into 288x1\n",
        "supple_model.add(Flatten())\n",
        "supple_model.add(Dense(512))\n",
        "supple_model.add(Activation('relu'))\n",
        "supple_model.add(Dropout(0.5))\n",
        "supple_model.add(Dense(num_classes))\n",
        "supple_model.add(Activation('softmax'))\n",
        "\n",
        "supple_model.summary()"
      ],
      "metadata": {
        "id": "Mk0eViy1AzAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc18d5d-2ac6-4b18-9420-83bd95ad0882"
      },
      "id": "Mk0eViy1AzAJ",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 32, 32, 32)        2432      \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 32, 32, 32)        25632     \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 16, 16, 32)        25632     \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 16, 16, 32)        25632     \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 8, 8, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               1049088   \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1133546 (4.32 MB)\n",
            "Trainable params: 1133546 (4.32 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005)\n",
        "\n",
        "\n",
        "supple_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "supple_model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=5,\n",
        "              validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "7kndgZjYAy9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6fe6fe5-ed98-40ce-f15a-64a32ea473df"
      },
      "id": "7kndgZjYAy9R",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 486s 310ms/step - loss: 1.6374 - accuracy: 0.4056 - val_loss: 1.2331 - val_accuracy: 0.5586\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 460s 294ms/step - loss: 1.2238 - accuracy: 0.5703 - val_loss: 1.5916 - val_accuracy: 0.4825\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 457s 293ms/step - loss: 1.0949 - accuracy: 0.6211 - val_loss: 1.0473 - val_accuracy: 0.6358\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 476s 305ms/step - loss: 1.0363 - accuracy: 0.6426 - val_loss: 1.2658 - val_accuracy: 0.5744\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 476s 304ms/step - loss: 1.0197 - accuracy: 0.6532 - val_loss: 1.2151 - val_accuracy: 0.6226\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c36c98389a0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "supple_model_2 = Sequential()\n",
        "\n",
        "## 5x5 convolution with 1x1 stride and 32 filters\n",
        "supple_model_2.add(Conv2D(64, (4, 4), strides=(1, 1), padding='same', input_shape=x_train.shape[1:]))\n",
        "supple_model_2.add(Activation('relu'))\n",
        "\n",
        "## 1x1 max pooling reduces to 3 x 3 x 32\n",
        "supple_model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "supple_model_2.add(Dropout(0.25))\n",
        "\n",
        "## Another 5x5 convolution with 1x1 stride and 32 filters\n",
        "supple_model_2.add(Conv2D(32, (4, 4), strides=(1, 1), padding='same'))\n",
        "supple_model_2.add(Activation('relu'))\n",
        "\n",
        "## Another 5x5 convolution with 1x1 stride and 64 filters\n",
        "supple_model_2.add(Conv2D(64, (4, 4), strides=(1, 1), padding='same'))\n",
        "supple_model_2.add(Activation('relu'))\n",
        "\n",
        "## 1x1 max pooling reduces to 3 x 3 x 32\n",
        "supple_model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "supple_model_2.add(Dropout(0.25))\n",
        "\n",
        "## Flatten turns 3x3x32 into 288x1\n",
        "supple_model_2.add(Flatten())\n",
        "supple_model_2.add(Dense(512))\n",
        "supple_model_2.add(Activation('relu'))\n",
        "supple_model_2.add(Dropout(0.5))\n",
        "supple_model_2.add(Dense(num_classes))\n",
        "supple_model_2.add(Activation('softmax'))\n",
        "\n",
        "supple_model_2.summary()"
      ],
      "metadata": {
        "id": "52MjfYlLAy6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d25b6b-7ca9-4e1d-e488-bcc85d09e14c"
      },
      "id": "52MjfYlLAy6v",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_72 (Conv2D)          (None, 32, 32, 64)        3136      \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_45 (MaxPooli  (None, 16, 16, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_73 (Conv2D)          (None, 16, 16, 32)        32800     \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_74 (Conv2D)          (None, 16, 16, 64)        32832     \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_46 (MaxPooli  (None, 8, 8, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 512)               2097664   \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2171562 (8.28 MB)\n",
            "Trainable params: 2171562 (8.28 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005)\n",
        "\n",
        "\n",
        "supple_model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "supple_model_2.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=5,\n",
        "              validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFn83pQXL9LZ",
        "outputId": "a1df91de-55c1-4ec0-c5dc-1f1c7dfd2424"
      },
      "id": "fFn83pQXL9LZ",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 288s 367ms/step - loss: 1.6576 - accuracy: 0.4002 - val_loss: 1.3675 - val_accuracy: 0.5135\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 290s 371ms/step - loss: 1.2490 - accuracy: 0.5592 - val_loss: 1.1834 - val_accuracy: 0.5824\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 291s 372ms/step - loss: 1.0769 - accuracy: 0.6221 - val_loss: 1.2516 - val_accuracy: 0.5713\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 276s 353ms/step - loss: 0.9714 - accuracy: 0.6635 - val_loss: 1.0203 - val_accuracy: 0.6504\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 277s 355ms/step - loss: 0.9099 - accuracy: 0.6858 - val_loss: 1.0631 - val_accuracy: 0.6315\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c36954ab8b0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "compact-still",
      "metadata": {
        "id": "compact-still"
      },
      "source": [
        "#### Conclusion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "desirable-jackson",
      "metadata": {
        "id": "desirable-jackson"
      },
      "source": [
        "This activity helped me comprehend a deeper understanding about convolutional neural networks (CNNs), I have learned the concept and techniques to apply it in this activity to help me finish the given tasks. I realized that the regularization techniques, optimization, and the architecture of the models can impact the performance of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab Link: https://colab.research.google.com/drive/1w_jHAtLp86oPp-cMvEGF3Tt7q0y6RI9k?usp=sharing"
      ],
      "metadata": {
        "id": "_IUUUCx9W050"
      },
      "id": "_IUUUCx9W050"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}